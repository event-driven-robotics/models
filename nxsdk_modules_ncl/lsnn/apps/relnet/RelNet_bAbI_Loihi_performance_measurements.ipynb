{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Â© 2018-2021 Intel Corporation All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions\n",
    "# are met:\n",
    "#   * Redistributions of source code must retain the above copyright\n",
    "#     notice, this list of conditions and the following disclaimer.\n",
    "#   * Redistributions in binary form must reproduce the above copyright\n",
    "#     notice, this list of conditions and the following disclaimer in\n",
    "#     the documentation and/or other materials provided with the\n",
    "#     distribution.\n",
    "#   * Neither the name of Intel Corporation nor the names of its\n",
    "#     contributors may be used to endorse or promote products derived\n",
    "#     from this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n",
    "# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n",
    "# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n",
    "# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n",
    "# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n",
    "# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n",
    "# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n",
    "# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n",
    "# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    "# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/pplank/nxsdk-nxsdk-submission/nxsdk-nxsdk/')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from logging import Filter, StreamHandler\n",
    "import nxsdk.api.n2a as nx\n",
    "from nxsdk.utils.env_var_context_manager import setEnvWithinContext\n",
    "from nxsdk.graph.processes.phase_enums import Phase\n",
    "from nxsdk.api.enums.api_enums import ProbeParameter\n",
    "from nxsdk.graph.monitor.probes import PerformanceProbeCondition\n",
    "from nxsdk_modules.lsnn.apps.relnet.data.loihi_chip_optimum_network_from_data import get_relational_network_placement_on_loihi\n",
    "\n",
    "from nxsdk_modules.lsnn.apps.relnet.data.loihi_final_placement_debug_for_FF_check_real_input import perform_LSNN_placement\n",
    "from nxsdk_modules.lsnn.apps.relnet.data.loihi_final_placement_debug_for_FF_check_real_input import perform_relnet_placement\n",
    "from nxsdk_modules.lsnn.apps.relnet.data.loihi_final_placement_debug_for_FF_check_real_input import perform_translation_layer_placement\n",
    "from nxsdk_modules.lsnn.apps.relnet.data.loihi_final_placement_debug_for_FF_check_real_input import perform_final_MLP_placement\n",
    "from nxsdk_modules.lsnn.apps.relnet.data.loihi_final_placement_debug_for_FF_check_real_input import perform_readout_placement\n",
    "from nxsdk_modules.lsnn.apps.relnet.data.loihi_final_placement_debug_for_FF_check_real_input import create_lsnn_output_spike_generators\n",
    "from nxsdk_modules.lsnn.apps.relnet.data.loihi_final_placement_debug_for_FF_check_real_input import create_input_mask_spike_generator\n",
    "\n",
    "from nxsdk_modules.lsnn.apps.relnet.data.loihi_placement_param_search import MAX_N_SENTENCES\n",
    "from IPython.core import ultratb\n",
    "sys.excepthook = ultratb.FormattedTB(mode='Verbose',\n",
    "     color_scheme='Linux', call_pdb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task parameters\n",
    "# set the sample size for the run (-> need to be consistent with SNIP)\n",
    "batch_size = 250\n",
    "# choose task of bAbI dataset (-> needs to have # batch_size of length max_len)\n",
    "task = 'qa17'\n",
    "# choose length of sentences\n",
    "max_len = 2\n",
    "\n",
    "# other parameters\n",
    "n_input_steps = 14\n",
    "n_sim_steps = 37\n",
    "\n",
    "time_steps_between_mask_spikes = 17\n",
    "steps_per_word = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(task, max_len, batch_size):\n",
    "    \"\"\"Generates input spikes for the network.\"\"\"\n",
    "\n",
    "    data_file_path = \"data/full_dataset.p\"\n",
    "    with open(data_file_path, 'rb') as fin:\n",
    "        data_dict = pickle.load(fin)\n",
    "\n",
    "    # parameters\n",
    "    num_words = 180\n",
    "    max_sentence_len = 11\n",
    "    max_story_len = 20\n",
    "\n",
    "    input_period_len = max_sentence_len*steps_per_word + n_sim_steps - n_input_steps + 10  # for non-overlapping LSNN and Relnets\n",
    "\n",
    "    story_spike_list = []\n",
    "    query_spike_list = []\n",
    "    answers = []\n",
    "    sentence_exists_mask_list = []\n",
    "\n",
    "    # only stories of length max_len\n",
    "    ids = np.where(data_dict['by_task'][task]['story_lengths'] == max_len)\n",
    "\n",
    "    for i in range(0, 250):\n",
    "\n",
    "        story = data_dict['by_task'][task]['stories'][ids][i]\n",
    "        query = data_dict['by_task'][task]['queries'][ids][i]\n",
    "        answer = data_dict['by_task'][task]['predicted_answer'][ids][i]\n",
    "\n",
    "        sentence_exists_mask = np.any(story, axis=1)\n",
    "\n",
    "        spikes = np.zeros((max_story_len, input_period_len, num_words))\n",
    "        query_spikes = np.zeros((input_period_len, num_words))\n",
    "\n",
    "        # story spikes\n",
    "        for i in range(0, 20):\n",
    "            # spikes\n",
    "            for num, neuron in enumerate(story[i]):\n",
    "                if neuron > 0:\n",
    "                    for s in range((num * steps_per_word), (num*steps_per_word) + steps_per_word):\n",
    "                        spikes[i, s, neuron-1] = 1\n",
    "\n",
    "        # query spikes\n",
    "        for num, neuron in enumerate(query):\n",
    "            if neuron > 0:\n",
    "                for s in range((num * steps_per_word), (num*steps_per_word) + steps_per_word):\n",
    "                    query_spikes[s, neuron-1] = 1\n",
    "\n",
    "        answers.append(answer)\n",
    "        story_spike_list.append(spikes)\n",
    "        query_spike_list.append(query_spikes)\n",
    "        sentence_exists_mask_list.append(sentence_exists_mask)\n",
    "\n",
    "    story_spikes = np.concatenate(story_spike_list, axis=1)\n",
    "    query_spikes = np.concatenate(query_spike_list, axis=0)\n",
    "    sentence_exists_mask = np.stack(sentence_exists_mask_list)\n",
    "\n",
    "    return story_spikes, query_spikes, sentence_exists_mask, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pplank/nxsdk-nxsdk-submission/nxsdk-nxsdk/nxsdk_modules/lsnn/apps/relnet/data/loihi_chip_optimum_network_from_data.py:565: RuntimeWarning: divide by zero encountered in floor_divide\n",
      "  fanout_count = output_axon_count//neuron_count\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data_file_path = \"data/full_dataset.p\"\n",
    "with open(data_file_path, 'rb') as fin:\n",
    "    data_dict = pickle.load(fin)\n",
    "    #plot_data = data_dict['plot_data']\n",
    "    cell_data = data_dict['cell_data']\n",
    "    \n",
    "# needed for weights/placement\n",
    "stories_LSNN_cell_data = cell_data['stories_LSNN_cell_data']\n",
    "queries_LSNN_cell_data = cell_data['queries_LSNN_cell_data']\n",
    "relational_function_cell_data = cell_data['relational_function_cell_data']\n",
    "quantization_cell_data = cell_data['quantization_cell_data']\n",
    "final_MLP_cell_data = cell_data['final_MLP_cell_data']\n",
    "readout_cell_data = cell_data['readout_cell_data']\n",
    "\n",
    "# get input spikes\n",
    "stories_LSNN_input_spikes, queries_LSNN_input_spikes, sentence_exists_mask, target_answers = process_input(task, max_len, batch_size)\n",
    "\n",
    "batch_period = int(stories_LSNN_input_spikes.shape[1] / batch_size)\n",
    "assert batch_period == stories_LSNN_input_spikes.shape[1] / batch_size\n",
    "\n",
    "lsnn_input_time_steps = batch_period - 10 + n_input_steps - n_sim_steps  # 330\n",
    "\n",
    "## just for mask!!\n",
    "max_n_sentences = 20\n",
    "\n",
    "assert sentence_exists_mask.shape == (batch_size, max_n_sentences)\n",
    "\n",
    "# without pause between samples\n",
    "input_mask_spikes = np.zeros((batch_size, max_n_sentences, batch_period))\n",
    "input_spike_times = np.arange(lsnn_input_time_steps-n_input_steps+1, lsnn_input_time_steps-n_input_steps+1+n_sim_steps, time_steps_between_mask_spikes)\n",
    "for t in input_spike_times:\n",
    "    input_mask_spikes[:, :, t] = 1.0\n",
    "input_mask_spikes *= (sentence_exists_mask[:, :, None] == 0.0).astype(np.float32)\n",
    "input_mask_spikes = np.transpose(input_mask_spikes, [0, 2, 1])\n",
    "input_mask_spikes = np.reshape(input_mask_spikes, (batch_size*batch_period, max_n_sentences))\n",
    "\n",
    "assert input_mask_spikes.shape[0] == stories_LSNN_input_spikes.shape[1]\n",
    "\n",
    "\n",
    "# Here we get the core connection arrays as according to the placement algorithms\n",
    "((lsnn_sentence_core_connection_array, sentence_n_cores_total),\n",
    " (lsnn_question_core_connection_array, question_n_cores_total),\n",
    " ((input_mask_core, input_mask_relay_cores, input_mask_to_relay_connections), _),\n",
    " (relnet_init_core_connection_array, relnet_init_n_cores),\n",
    " (relnet_intermediate_core_connection_array, relnet_intermediate_n_cores),\n",
    " (translation_layer_core_connection, translation_layer_n_cores),\n",
    " (final_MLP_core_connection, final_MLP_n_cores),\n",
    " (readout_core_connection, readout_n_cores)) = \\\n",
    "    get_relational_network_placement_on_loihi(cell_data,\n",
    "                                              use_optimal_intermediate_placement=True,\n",
    "                                              use_cores_for_input=False)\n",
    "\n",
    "# Here we connect to the cell and create the network net\n",
    "net = nx.NxNet()\n",
    "\n",
    "########### figure out network size from input #########################\n",
    "max_sentences = int(max_len)\n",
    "n_sentence1 = max_sentences\n",
    "n_sentence2 = max_sentences\n",
    "\n",
    "\n",
    "############ LSNN and relay layer ############\n",
    "# Here we place the sentence LSNN's according to the mapping created above\n",
    "(sentence_lsnn_id_to_neuron_group_map, sentence_lsnn_neuron_group_array,\n",
    " sentence_lsnn_id_to_relay_neuron_group_map, sentence_relay_neuron_group_array,\n",
    " sentence_lsnn_id_to_spike_gen_map, sentence_spike_generator_array) = \\\n",
    "    perform_LSNN_placement(lsnn_sentence_core_connection_array,\n",
    "                           stories_LSNN_cell_data,\n",
    "                           stories_LSNN_input_spikes,\n",
    "                           5.0, net, max_sentences)\n",
    "\n",
    "# Here we place the question LSNN's according to the mapping created above\n",
    "(question_lsnn_id_to_neuron_group_map, question_lsnn_neuron_group_array,\n",
    " question_lsnn_id_to_relay_neuron_group_map, question_relay_neuron_group_array,\n",
    " question_lsnn_id_to_spike_gen_map, question_spike_generator_array) = \\\n",
    "    perform_LSNN_placement(lsnn_question_core_connection_array,\n",
    "                           queries_LSNN_cell_data,\n",
    "                           queries_LSNN_input_spikes,\n",
    "                           5.0, net)\n",
    "\n",
    "# TODO: figure out how to parameterise the weights etc. to really be able to scale the network config\n",
    "input_mask_spike_gen, input_mask_id_to_spike_gen_map = create_input_mask_spike_generator(input_mask_core,\n",
    "                                                                                         input_mask_relay_cores,\n",
    "                                                                                         input_mask_to_relay_connections,\n",
    "                                                                                         input_mask_spikes,\n",
    "                                                                                         net, max_sentences)\n",
    "\n",
    "# map for the relational layer\n",
    "combined_lsnn_id_to_output_spike_gen_map = {**sentence_lsnn_id_to_relay_neuron_group_map,\n",
    "                                            **question_lsnn_id_to_relay_neuron_group_map,\n",
    "                                            **input_mask_id_to_spike_gen_map}\n",
    "\n",
    "assert all(x.compileParams.logicalCoreId == id_ for id_, x in sentence_lsnn_id_to_relay_neuron_group_map.items())\n",
    "assert all(x.compileParams.logicalCoreId == id_ for id_, x in question_lsnn_id_to_relay_neuron_group_map.items())\n",
    "\n",
    "\n",
    "############ relational FF layers ############\n",
    "relational_function_neuron_group_arrays = []\n",
    "relational_function_id_to_neuron_group_maps = []\n",
    "\n",
    "# layer 1 of the FF network\n",
    "input_id_to_neuron_group_map = combined_lsnn_id_to_output_spike_gen_map\n",
    "\n",
    "(relnet_neuron_group_array, relnet_init_id_to_neuron_group_map) = perform_relnet_placement(input_id_to_neuron_group_map,\n",
    "                                                                                           relnet_init_core_connection_array,\n",
    "                                                                                           relational_function_cell_data[0],\n",
    "                                                                                           net, n_sentence1, n_sentence2)\n",
    "\n",
    "relational_function_neuron_group_arrays.append(relnet_neuron_group_array)\n",
    "relational_function_id_to_neuron_group_maps.append(relnet_init_id_to_neuron_group_map)\n",
    "\n",
    "# layer 2 of the FF network\n",
    "(relnet_neuron_group_array, relnet_id_to_neuron_group_map) =     perform_relnet_placement(relnet_init_id_to_neuron_group_map,\n",
    "                             relnet_intermediate_core_connection_array[0],\n",
    "                             relational_function_cell_data[1],\n",
    "                             net, n_sentence1, n_sentence2)\n",
    "\n",
    "relational_function_neuron_group_arrays.append(relnet_neuron_group_array)\n",
    "relational_function_id_to_neuron_group_maps.append(relnet_id_to_neuron_group_map)\n",
    "\n",
    "# layer 3 of the FF network\n",
    "(relnet_neuron_group_array, relnet_id_to_neuron_group_map) =     perform_relnet_placement(relnet_id_to_neuron_group_map,\n",
    "                             relnet_intermediate_core_connection_array[1],\n",
    "                             relational_function_cell_data[2],\n",
    "                             net, n_sentence1, n_sentence2)\n",
    "\n",
    "relational_function_neuron_group_arrays.append(relnet_neuron_group_array)\n",
    "relational_function_id_to_neuron_group_maps.append(relnet_id_to_neuron_group_map)\n",
    "\n",
    "# layer 4 of the FF network\n",
    "(relnet_neuron_group_array, relnet_id_to_neuron_group_map) =     perform_relnet_placement(relnet_id_to_neuron_group_map,\n",
    "                             relnet_intermediate_core_connection_array[2],\n",
    "                             relational_function_cell_data[3],\n",
    "                             net, n_sentence1, n_sentence2)\n",
    "\n",
    "relational_function_neuron_group_arrays.append(relnet_neuron_group_array)\n",
    "relational_function_id_to_neuron_group_maps.append(relnet_id_to_neuron_group_map)\n",
    "\n",
    "############ translational layer ############\n",
    "(translation_layer_neuron_group_tuple,\n",
    " translation_layer_id_to_neuron_group_map) = \\\n",
    "    perform_translation_layer_placement(\n",
    "        relational_function_id_to_neuron_group_maps[-1],\n",
    "        translation_layer_core_connection,\n",
    "        quantization_cell_data, net, n_sentence1, n_sentence2)\n",
    "\n",
    "input_id_to_neuron_group_map = translation_layer_id_to_neuron_group_map\n",
    "\n",
    "############ Readout FF layers ############\n",
    "final_MLP_neuron_group_list = []\n",
    "for i in range(len(final_MLP_cell_data)):\n",
    "    (final_MLP_neuron_group_tuple,\n",
    "     final_MLP_id_to_neuron_group_map) = perform_final_MLP_placement(input_id_to_neuron_group_map,\n",
    "                                                                     final_MLP_core_connection[i],\n",
    "                                                                     final_MLP_cell_data[i], net)\n",
    "    final_MLP_neuron_group_list.append(final_MLP_neuron_group_tuple)\n",
    "    input_id_to_neuron_group_map = final_MLP_id_to_neuron_group_map\n",
    "\n",
    "############ final readout layer ############\n",
    "(readout_neuron_group_tuple,\n",
    " readout_id_to_neuron_group_map) = \\\n",
    "    perform_readout_placement(input_id_to_neuron_group_map,\n",
    "                              readout_core_connection,\n",
    "                              readout_cell_data, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relay_sentences_core_ids = np.concatenate([np.concatenate([np.array([core.id for core in relay_copy])\n",
    "                                                           for relay_copy in x.cores.relay])\n",
    "                                           for x in lsnn_sentence_core_connection_array.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6401f275bf46>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  relay_sentences_core_ids = np.array(relay_sentences_core_ids).ravel()\n",
      "<ipython-input-7-6401f275bf46>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  relay_questions_core_ids = np.array(relay_questions_core_ids).ravel()\n"
     ]
    }
   ],
   "source": [
    "# get core ids of lsnn and relay networks of sentences and questions for the SNIPs\n",
    "lsnn_sentences_core_ids = [[core.id for core in x.cores.lsnn] for x in lsnn_sentence_core_connection_array.ravel()]\n",
    "relay_sentences_core_ids = [[[core.id for core in relay_copy] for relay_copy in x.cores.relay] for x in lsnn_sentence_core_connection_array.ravel()]\n",
    "\n",
    "lsnn_questions_core_ids = [core.id for core in lsnn_question_core_connection_array.cores.lsnn]\n",
    "relay_questions_core_ids = [[core.id for core in relay_copy] for relay_copy in lsnn_question_core_connection_array.cores.relay]\n",
    "\n",
    "lsnn_sentences_core_ids = np.array(lsnn_sentences_core_ids).ravel()\n",
    "lsnn_questions_core_ids = np.array(lsnn_questions_core_ids).ravel()\n",
    "relay_sentences_core_ids = np.array(relay_sentences_core_ids).ravel()\n",
    "relay_questions_core_ids = np.array(relay_questions_core_ids).ravel()\n",
    "\n",
    "## new\n",
    "relay_sentences_core_ids = np.concatenate([np.concatenate([np.array([core.id for core in relay_copy])\n",
    "                                                           for relay_copy in x.cores.relay])\n",
    "                                           for x in lsnn_sentence_core_connection_array.ravel()])\n",
    "\n",
    "relay_questions_core_ids = np.concatenate([np.array([core.id for core in relay_copy]) \n",
    "                                           for relay_copy in lsnn_question_core_connection_array.cores.relay])\n",
    "\n",
    "lsnn_core_ids_list = [lsnn_sentences_core_ids, lsnn_questions_core_ids]\n",
    "relay_core_ids_list = [relay_sentences_core_ids, relay_questions_core_ids]\n",
    "\n",
    "# get readout core ids\n",
    "readout_core_ids = [core.id for core in readout_core_connection.cores]\n",
    "readout_core_ids_list = [np.array(readout_core_ids).ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all core ids which are not LSNNs or relay neurons (for reset after classification)\n",
    "assert len(readout_core_ids) == 1\n",
    "highest_core_id = readout_core_ids[0]\n",
    "lowest_core_id = 0 \n",
    "\n",
    "lsnn_core_ids = np.concatenate(lsnn_core_ids_list)\n",
    "relay_core_ids = np.concatenate(relay_core_ids_list)\n",
    "\n",
    "lsnn_relay_core_ids = np.concatenate([lsnn_core_ids, relay_core_ids])\n",
    "\n",
    "# these core ids needs to be reset\n",
    "reset_core_ids = []\n",
    "for i in range(lowest_core_id, highest_core_id):\n",
    "    if i not in lsnn_relay_core_ids:\n",
    "        reset_core_ids.append(i)\n",
    "\n",
    "reset_core_ids_list = [np.array(reset_core_ids).ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get chip_id and chip_core_id from core_ids\n",
    "def get_chip_core_dict(core_ids_list):\n",
    "    chip_core_dict = {}\n",
    "\n",
    "    for ids in core_ids_list:\n",
    "        chip_ids = np.floor(ids/128).astype(np.int32)\n",
    "        chip_core_ids = ids%128\n",
    "        \n",
    "        for chip in range(0, np.max(chip_ids)+1):\n",
    "            if chip in chip_core_dict.keys():\n",
    "                chip_core_dict[chip].extend(chip_core_ids[np.where(chip_ids==chip)])\n",
    "            else:\n",
    "                if len(chip_core_ids[np.where(chip_ids==chip)].tolist()) > 0:\n",
    "                    chip_core_dict[chip] = chip_core_ids[np.where(chip_ids==chip)].tolist()\n",
    "                \n",
    "    return chip_core_dict\n",
    "\n",
    "lsnn_chip_core_dict = get_chip_core_dict(lsnn_core_ids_list)\n",
    "relay_chip_core_dict = get_chip_core_dict(relay_core_ids_list)\n",
    "readout_chip_core_dict = get_chip_core_dict(readout_core_ids_list)\n",
    "reset_chip_core_dict = get_chip_core_dict(reset_core_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_lsnn_relay_snips(core_id_list, snip_dir):\n",
    "    # Create SNIP for LSNN/relay procedure\n",
    "    lsnn_channel_dict = {}\n",
    "    relay_channel_dict = {}\n",
    "        \n",
    "    for chip_id in set(core_id_list):\n",
    "        mgmtSnip = board.createSnip(\n",
    "            name=\"runMgmt\",\n",
    "            includeDir=snip_dir,\n",
    "            cFilePath=snip_dir + \"snip_mgmt.c\",\n",
    "            funcName=\"run_mgmt\", \n",
    "            guardName=\"do_mgmt\", \n",
    "            phase=Phase.EMBEDDED_MGMT,\n",
    "            chipId=chip_id)\n",
    "\n",
    "        # Create a channel from super host to Lakemont for sending core ids of lsnn networks\n",
    "        lsnn_channel = board.createChannel(bytes('lsnn_id_ch_' + str(chip_id), 'utf-8'), numElements=1,\n",
    "                                           messageSize=128*4)\n",
    "        lsnn_channel.connect(None, mgmtSnip)\n",
    "\n",
    "        # Create a channel from super host to Lakemont for sending core ids of relay networks\n",
    "        relay_channel = board.createChannel(bytes('relay_id_ch_' + str(chip_id), 'utf-8'), numElements=1,\n",
    "                                            messageSize=128*4)\n",
    "        relay_channel.connect(None, mgmtSnip)\n",
    "\n",
    "        lsnn_channel_dict[chip_id] = lsnn_channel\n",
    "        relay_channel_dict[chip_id] = relay_channel\n",
    "    \n",
    "    return lsnn_channel_dict, relay_channel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_readout_snips(reaout_core_id_list, readout_chip_core_dict, snip_dir):\n",
    "    # Create SNIP for readout procedure\n",
    "    \n",
    "    readout_channel_dict = {}\n",
    "    \n",
    "    for chip_id in set(reaout_core_id_list):\n",
    "        mgmtSnip = board.createSnip(\n",
    "            name=\"runMgmt\",\n",
    "            includeDir=snip_dir,\n",
    "            cFilePath=snip_dir + \"readout_snip_mgmt.c\",\n",
    "            funcName=\"run_mgmt\", \n",
    "            guardName=\"do_mgmt\", \n",
    "            phase=Phase.EMBEDDED_MGMT,\n",
    "            chipId=chip_id)\n",
    "\n",
    "        # Create a channel from super host to Lakemont for sending core ids of lsnn networks\n",
    "        if len(readout_chip_core_dict[chip_id]) > 0:\n",
    "            readout_channel = board.createChannel(bytes('readout_id_ch_' + str(chip_id), 'utf-8'), numElements=1,\n",
    "                                               messageSize=128*4)\n",
    "            readout_channel.connect(None, mgmtSnip)\n",
    "        else:\n",
    "            readout_channel = None\n",
    "\n",
    "        readout_channel_dict[chip_id] = readout_channel\n",
    "        \n",
    "        # configure init channel\n",
    "        num_output = 181\n",
    "        readout_init_channel = board.createChannel(b'output_neurons', numElements=4 * num_output, messageSize=4)\n",
    "        readout_init_channel.connect(None, mgmtSnip)\n",
    "\n",
    "        # configure classification channel\n",
    "        classification_channel = board.createChannel(b'classifications', numElements=1, messageSize=batch_size*4)\n",
    "        classification_channel.connect(mgmtSnip, None)\n",
    "        \n",
    "    return readout_channel_dict, readout_init_channel, classification_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_reset_snips(reset_chip_core_dict, snip_dir):\n",
    "    # Create SNIP for reset procedure\n",
    "    \n",
    "    reset_channel_dict = {}\n",
    "    \n",
    "    for chip_id in set(reset_chip_core_dict.keys()):\n",
    "        mgmtSnip = board.createSnip(\n",
    "            name=\"runMgmt\",\n",
    "            includeDir=snip_dir,\n",
    "            cFilePath=snip_dir + \"snip_reset.c\",\n",
    "            funcName=\"run_mgmt\", \n",
    "            guardName=\"do_mgmt\", \n",
    "            phase=Phase.EMBEDDED_MGMT,\n",
    "            chipId=chip_id,\n",
    "            lmtId=1)\n",
    "\n",
    "        # Create a channel from super host to Lakemont for sending core ids which should be reset\n",
    "        if len(reset_chip_core_dict[chip_id]) > 0:\n",
    "            readout_channel = board.createChannel(bytes('reset_id_ch_' + str(chip_id), 'utf-8'), numElements=1,\n",
    "                                               messageSize=128*4)\n",
    "            readout_channel.connect(None, mgmtSnip)\n",
    "        else:\n",
    "            readout_channel = None\n",
    "\n",
    "        reset_channel_dict[chip_id] = readout_channel\n",
    "    \n",
    "    return reset_channel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsnn_relay_channel_write(core_id_list, lsnn_chip_core_dict, relay_chip_core_dict, lsnn_channel_dict, relay_channel_dict):\n",
    "    default = list(np.zeros(128, dtype=np.int32) - 1)\n",
    "    # write core ids to the channels\n",
    "    for chip_id in set(core_id_list):\n",
    "        # print(chip_id)\n",
    "        if chip_id in lsnn_chip_core_dict:\n",
    "            # print((lsnn_chip_core_dict[chip_id] + default)[:128])\n",
    "            lsnn_channel_dict[chip_id].write(1, (lsnn_chip_core_dict[chip_id] + default)[:128])\n",
    "        else:\n",
    "            # there needs to be written something, otherwise the SNIP stalls\n",
    "            lsnn_channel_dict[chip_id].write(1, default)\n",
    "        if chip_id in relay_chip_core_dict:\n",
    "            # print((relay_chip_core_dict[chip_id] + default)[:128])\n",
    "            relay_channel_dict[chip_id].write(1, (relay_chip_core_dict[chip_id] + default)[:128])\n",
    "        else:\n",
    "            # there needs to be written something, otherwise the SNIP stalls\n",
    "            relay_channel_dict[chip_id].write(1, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readout_channel_write(readout_chip_core_dict, readout_channel_dict, readout_init_channel):\n",
    "    default = list(np.zeros(128, dtype=np.int32) - 1)\n",
    "    chip_id_list = list(readout_chip_core_dict.keys())\n",
    "    for chip_id in set(chip_id_list):\n",
    "        readout_channel_dict[chip_id].write(1, (readout_chip_core_dict[chip_id] + default)[:128])\n",
    "        \n",
    "        # TODO: change to a more flexible layout if output neurons do not fit on one core/chip\n",
    "        board_id = 0\n",
    "        core_id = readout_chip_core_dict[chip_id][0]  # Assumes only 1 core!\n",
    "        num_output = 181\n",
    "        for cx_id in range(num_output):\n",
    "            readout_init_channel.write(4, [board_id, chip_id, core_id, cx_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_channel_write(reset_chip_core_dict, reset_channel_dict):\n",
    "    default = list(np.zeros(128, dtype=np.int32) - 1)\n",
    "    chip_id_list = list(reset_chip_core_dict.keys())\n",
    "    \n",
    "    for chip_id in set(chip_id_list):\n",
    "        reset_channel_dict[chip_id].write(1, (reset_chip_core_dict[chip_id] + default)[:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove chip 0 and chip 21 from the reset list (reset handled in their respective SNIP)\n",
    "del reset_chip_core_dict[0]\n",
    "del reset_chip_core_dict[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = batch_size * batch_period + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:  SLURM is being run in background\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:  Connecting to 134.134.68.22:45329\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Host server up..............Done 0.25s\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Encoding axons/synapses.....Done 0.87s\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Compiling Embedded snips....Done 16.50s\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Compiling MPDS Registers....Done 1.52ms\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Compiling Register Probes...Done 0.76ms\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Compiling Spike Probes......Done 0.63ms\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=0 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip0_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=1 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip1_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=1 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip1_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=2 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip2_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=2 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip2_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=3 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip3_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=3 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip3_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=4 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip4_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=4 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip4_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=5 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip5_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=5 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip5_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=6 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip6_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=6 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip6_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=7 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip7_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=7 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip7_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=8 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip8_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=8 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip8_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=9 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip9_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=9 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip9_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=10 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip10_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=10 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip10_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=11 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip11_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=11 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip11_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=12 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip12_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=12 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip12_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=13 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip13_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=13 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip13_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=14 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip14_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=14 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip14_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=15 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip15_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=15 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip15_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=16 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip16_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=16 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip16_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=17 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip17_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=17 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip17_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=18 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip18_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=18 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip18_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=19 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip19_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=19 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip19_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=20 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip20_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=20 cpu=1 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip20_lmt1.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=21 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/compilers/../../../temp/1628351903.884258/launcher_chip21_lmt0.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=22 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/../bin/arm/idle_chip.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Args chip=23 cpu=0 /home/pplank/lava_env/lib/python3.8/site-packages/nxsdk/driver/../bin/arm/idle_chip.bin --chips=22 --remote-relay=0 --epoch=0 --cpu-active-ratio=1 \n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  Nx...\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Booting up..................Done 7.26s\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Encoding probes.............Done 0.76ms\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Transferring probes.........Done 9.37ms\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Configuring registers.......Done 5.26s\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Transferring spikes.........Done 0.93s\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=22 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=23 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Executing...................Done 0.02s\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mDRV\u001b[0m:      Processing timeseries.......Done 0.12s\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=16 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=17 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=18 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=19 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=20 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=21 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=0 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=1 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=2 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=3 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=4 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=5 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=6 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=7 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=8 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=9 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=10 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=11 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=12 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=13 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=14 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=15 cpu=0 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=16 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=17 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=18 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=19 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=20 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=1 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=2 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=3 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=4 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=5 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=6 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=7 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=8 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=9 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=10 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=11 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=12 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=13 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=14 cpu=1 halted, status=0x0\n",
      "\u001b[1;30mINFO\u001b[0m:\u001b[34mHST\u001b[0m:  chip=15 cpu=1 halted, status=0x0\n"
     ]
    }
   ],
   "source": [
    "with setEnvWithinContext(PARTITION='nahuku32', BOARD='ncl-ghrd-01'):\n",
    "    # compile network\n",
    "    board = nx.N2Compiler().compile(net)\n",
    "\n",
    "    # Define directory where SNIP C-code is located\n",
    "    snip_dir = os.getcwd() + \"/snips/\"\n",
    "    \n",
    "    # Configure LSNN/relay SNIP\n",
    "    core_id_list = list(lsnn_chip_core_dict.keys()) + list(relay_chip_core_dict.keys())\n",
    "    lsnn_channel_dict, relay_channel_dict = configure_lsnn_relay_snips(core_id_list, snip_dir)\n",
    "    \n",
    "    # Configure readout SNIP\n",
    "    readout_channel_dict, readout_init_channel, classification_channel = configure_readout_snips(readout_chip_core_dict, \n",
    "                                                                                                 readout_chip_core_dict, \n",
    "                                                                                                 snip_dir)\n",
    "    \n",
    "    # Configure reset SNIPs (all other)\n",
    "    reset_channel_dict = configure_reset_snips(reset_chip_core_dict, snip_dir)\n",
    "        \n",
    "    # Performance probes\n",
    "    buffer_size = 1024\n",
    "    bin_size = int(2**np.ceil(np.log2(runtime/buffer_size))) # should be a power of 2\n",
    "\n",
    "    etProbe = board.probe(\n",
    "    probeType=ProbeParameter.ENERGY, \n",
    "    probeCondition=PerformanceProbeCondition(\n",
    "        tStart=1, \n",
    "        tEnd=runtime, \n",
    "        bufferSize=buffer_size, \n",
    "        binSize=bin_size)\n",
    "    )\n",
    "     \n",
    "    # Start driver\n",
    "    board.start()\n",
    "    \n",
    "    # write into channels for LSNN/relay SNIP\n",
    "    lsnn_relay_channel_write(core_id_list, lsnn_chip_core_dict, relay_chip_core_dict, lsnn_channel_dict, relay_channel_dict)\n",
    "    \n",
    "    # write into channels for readout SNIP\n",
    "    readout_channel_write(readout_chip_core_dict, readout_channel_dict, readout_init_channel)\n",
    "    \n",
    "    # write into channels for reset SNIP\n",
    "    reset_channel_write(reset_chip_core_dict, reset_channel_dict)\n",
    "        \n",
    "    # run network\n",
    "    board.run(runtime, True)\n",
    "\n",
    "    # read classifications\n",
    "    classifications = []\n",
    "    classifications.append(classification_channel.read(1))\n",
    "    \n",
    "    board.finishRun()\n",
    "    board.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = classifications[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of task qa17 for 250 samples of lenght 2: 100.0%\n"
     ]
    }
   ],
   "source": [
    "result = len(set(target_answers) & set(predictions)) / float(len(set(target_answers) | set(predictions))) * 100\n",
    "print(\"Classification accuracy of task {} for {} samples of lenght {}: {}%\".format(task, batch_size, max_len, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of time steps:  35752\n",
      "Total time (Âµs): 2276299.999999985\n",
      "Mean time per time step (Âµs): 63.66916536137797\n",
      "Time per inference (Âµs) (250 samples): 9105.19999999994\n",
      "\n",
      "Dynamic power (mW):  630.0983325449383\n",
      "Static power (mW):  191.14990814809457\n",
      "Total power (mW):  821.2482406930329\n",
      "\n",
      "Latency per inference (ms):  9.105199999999941\n",
      "Total energy per inference (mJ):  7.477629481158155\n",
      "EDP (ÂµJs):  68.0853119518408\n",
      "\n",
      "Power in detail:\n",
      "x86 static power (mW):  9.541154247711152\n",
      "x86 dynamic power (mW):  407.4348348767732\n",
      "Core static power (mW):  181.60875390038342\n",
      "Core dynamic power (mW):  222.66349766816512\n"
     ]
    }
   ],
   "source": [
    "total = etProbe.totalTimePerTimeStep[0:runtime]\n",
    "host = etProbe.hostTimePerTimeStep[0:runtime]\n",
    "\n",
    "effective = total - host\n",
    "\n",
    "latency = np.sum(effective) / batch_size\n",
    "print('Total number of time steps: ', runtime)\n",
    "print('Total time (Âµs):', np.sum(total))\n",
    "print('Mean time per time step (Âµs):', np.mean(total))\n",
    "print('Time per inference (Âµs) ({} samples): {}'.format(batch_size, latency))\n",
    "\n",
    "# EDP\n",
    "stats = board.energyTimeMonitor.powerProfileStats\n",
    "\n",
    "n_dynamic = stats['power']['core']['dynamic']\n",
    "n_static = stats['power']['core']['static']\n",
    "\n",
    "x86_dynamic = stats['power']['lakemont']['dynamic']\n",
    "x86_static = stats['power']['lakemont']['static']\n",
    "\n",
    "dynamic = n_dynamic + x86_dynamic\n",
    "static = n_static + x86_static\n",
    "\n",
    "total = dynamic + static\n",
    "energy = latency * total / 10**6\n",
    "edp = energy * latency / 1000\n",
    "print()\n",
    "print(\"Dynamic power (mW): \", dynamic)\n",
    "print(\"Static power (mW): \", static)\n",
    "print(\"Total power (mW): \", total)\n",
    "print()\n",
    "print(\"Latency per inference (ms): \", latency / 1000)\n",
    "print(\"Total energy per inference (mJ): \", energy)\n",
    "print(\"EDP (ÂµJs): \", edp)\n",
    "print()\n",
    "print(\"Power in detail:\")\n",
    "print(\"x86 static power (mW): \", x86_static)\n",
    "print(\"x86 dynamic power (mW): \", x86_dynamic)\n",
    "print(\"Core static power (mW): \", n_static)\n",
    "print(\"Core dynamic power (mW): \", n_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
